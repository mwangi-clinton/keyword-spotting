{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1c3a8d-999c-411e-8db8-5036801368d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/capstor/scratch/cscs/ckuya\n"
     ]
    }
   ],
   "source": [
    "%cd /capstor/scratch/cscs/ckuya/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ab7fee6-111e-4307-b8e1-e99871dfa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf064d-a11a-4f2c-bbf2-06e5e16094a3",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be4fafdf-3208-4e1d-be56-35f5125ce571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFeatureDataset(Dataset):\n",
    "    def __init__(self, root_dir,\n",
    "                 sr=16000,\n",
    "                 n_fft=2048,\n",
    "                 hop_percent=0.0,\n",
    "                 win_length=320,\n",
    "                 n_mels=40,\n",
    "                 n_mfcc=13,\n",
    "                 max_len=None,\n",
    "                 exclude_folders=None):\n",
    "        \"\"\"\n",
    "        root_dir:  top‐level folder containing one subfolder per class\n",
    "        max_len:   maximum time‐frames to pad/truncate to\n",
    "        exclude_folders: list of subfolders to skip (e.g. ['_background_noise_'])\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.root_dir       = root_dir\n",
    "        self.sr             = sr\n",
    "        self.n_fft          = n_fft\n",
    "        self.win_length     = win_length\n",
    "        self.hop_length     = int(win_length * (1-hop_percent))\n",
    "        self.n_mels         = n_mels\n",
    "        self.n_mfcc         = n_mfcc\n",
    "        self.max_len        = max_len\n",
    "        self.exclude_folders= set(exclude_folders or [])\n",
    "\n",
    "        self._prepare_dataset()\n",
    "\n",
    "    def _prepare_dataset(self):\n",
    "        # 1) find all subfolders (classes), filter excludes\n",
    "        labels = sorted([\n",
    "            d for d in os.listdir(self.root_dir)\n",
    "            if os.path.isdir(os.path.join(self.root_dir, d))\n",
    "               and d not in self.exclude_folders\n",
    "        ])\n",
    "        # 2) build label→index map\n",
    "        self.label_to_idx = {lab: idx for idx, lab in enumerate(labels)}\n",
    "\n",
    "        # 3) walk filesystem\n",
    "        self.samples = []\n",
    "        for lab in labels:\n",
    "            folder = os.path.join(self.root_dir, lab)\n",
    "            for fn in os.listdir(folder):\n",
    "                if fn.lower().endswith(('.wav','.mp3')):\n",
    "                    self.samples.append((os.path.join(folder, fn),\n",
    "                                         self.label_to_idx[lab]))\n",
    "\n",
    "        # 4) sanity\n",
    "        N = len(self.label_to_idx)\n",
    "        self.samples = [s for s in self.samples if 0 <= s[1] < N]\n",
    "        print(f\"[Dataset] Found {len(self.samples)} files \"\n",
    "              f\"under {N} classes: {labels}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _extract_features(self, path):\n",
    "        y, _ = librosa.load(path, sr=self.sr)\n",
    "        # Mel-spectrogram\n",
    "        m = librosa.feature.melspectrogram(\n",
    "            y=y, sr=self.sr,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length,\n",
    "            n_mels=self.n_mels)\n",
    "        log_mel = librosa.power_to_db(m)\n",
    "        # MFCC\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            y=y, sr=self.sr,\n",
    "            n_mfcc=self.n_mfcc,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.win_length)\n",
    "        # normalize\n",
    "        log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-8)\n",
    "        mfcc    = (mfcc    - mfcc.mean())    / (mfcc.std()    + 1e-8)\n",
    "        # pad / truncate in time\n",
    "        if self.max_len is not None:\n",
    "            T = log_mel.shape[1]\n",
    "            if T >= self.max_len:\n",
    "                log_mel = log_mel[:, :self.max_len]\n",
    "                mfcc    = mfcc   [:, :self.max_len]\n",
    "            else:\n",
    "                pw = self.max_len - T\n",
    "                log_mel = np.pad(log_mel, ((0,0),(0,pw)), mode='constant')\n",
    "                mfcc    = np.pad(mfcc,    ((0,0),(0,pw)), mode='constant')\n",
    "        return log_mel, mfcc\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, lab = self.samples[idx]\n",
    "        log_mel, mfcc = self._extract_features(path)\n",
    "        return {\n",
    "            'mel':   torch.FloatTensor(log_mel),   # (n_mels, T)\n",
    "            'mfcc':  torch.FloatTensor(mfcc),      # (n_mfcc, T)\n",
    "            'label': torch.LongTensor([lab]).squeeze()\n",
    "        }\n",
    "\n",
    "def get_dataloaders(root_dir,\n",
    "                    mel_dim     = 40,\n",
    "                    mfcc_dim    = 13,\n",
    "                    max_len     = 20,\n",
    "                    batch_size  = 256,\n",
    "                    val_frac    = 0.2,\n",
    "                    num_workers = 4,\n",
    "                    exclude_folders = ['_background_noise_']):\n",
    "    \"\"\"\n",
    "    Returns: train_loader, val_loader, num_classes, label_to_idx\n",
    "    \"\"\"\n",
    "    ds = AudioFeatureDataset(\n",
    "        root_dir        = root_dir,\n",
    "        n_mels          = mel_dim,\n",
    "        n_mfcc          = mfcc_dim,\n",
    "        max_len         = max_len,\n",
    "        exclude_folders = exclude_folders\n",
    "    )\n",
    "    num_classes = len(ds.label_to_idx)\n",
    "    n_val  = int(len(ds) * val_frac)\n",
    "    n_train= len(ds) - n_val\n",
    "    train_ds, val_ds = random_split(ds, [n_train, n_val])\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=batch_size,\n",
    "        shuffle=True,  num_workers=num_workers, pin_memory=True)\n",
    "    val_loader   = DataLoader(\n",
    "        val_ds,   batch_size=batch_size,\n",
    "        shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    return train_loader, val_loader, num_classes, ds.label_to_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684050c-f9c5-4cd7-911b-8f8e332ecf61",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79c324df-b7ae-466e-978f-59391566f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MelCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),  # (B, 1, 40, 20) → (B, 16, 40, 20)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                            # (B, 16, 20, 10)\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # (B, 32, 20, 10)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                             # (B, 32, 10, 5)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                                # (B, 32*10*5)\n",
    "            nn.Linear(32 * 10 * 5, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class SbuLSTMClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_mels: int            = 40,\n",
    "                 hidden_dim: int        = 128,\n",
    "                 uni_layers: int        = 1,\n",
    "                 num_classes: int       = 30,\n",
    "                 dropout: float         = 0.3):\n",
    "        super(SbuLSTMClassifier, self).__init__()\n",
    "        # 1) Bidirectional LSTM feature extractor\n",
    "        self.bdlstm = nn.LSTM(\n",
    "            input_size   = n_mels,\n",
    "            hidden_size  = hidden_dim,\n",
    "            num_layers   = 1,\n",
    "            batch_first  = True,\n",
    "            bidirectional= True\n",
    "        )\n",
    "        # 2) Unidirectional LSTM for forward‐only refinement\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size  = 2 * hidden_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers  = uni_layers,\n",
    "            batch_first = True,\n",
    "            bidirectional = False\n",
    "        )\n",
    "        # 3) MLP classifier on the last time step\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, 1, n_mels, T)\n",
    "        B, C, F, T = x.shape\n",
    "        # remove channel dim → (B, F, T), then time‐first → (B, T, F)\n",
    "        x = x.view(B, F, T).permute(0, 2, 1)\n",
    "\n",
    "        # 1) Bidirectional LSTM → (B, T, 2*hidden_dim)\n",
    "        x, _ = self.bdlstm(x)\n",
    "\n",
    "        # 2) Unidirectional LSTM → (B, T, hidden_dim)\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # 3) Take last time step features\n",
    "        last = x[:, -1, :]              # (B, hidden_dim)\n",
    "\n",
    "        # 4) Classify\n",
    "        logits = self.classifier(last)  # (B, num_classes)\n",
    "        return logits\n",
    "\n",
    "class SbuLSTMFusion(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_mels: int       = 40,\n",
    "                 n_mfcc: int       = 13,\n",
    "                 hidden_dim: int   = 128,\n",
    "                 uni_layers: int   = 1,\n",
    "                 num_classes: int  = 30,\n",
    "                 dropout: float    = 0.3):\n",
    "        super().__init__()\n",
    "        # Bi-LSTM on Mel\n",
    "        self.bdlstm_mel = nn.LSTM(\n",
    "            input_size    = n_mels,\n",
    "            hidden_size   = hidden_dim,\n",
    "            num_layers    = 1,\n",
    "            batch_first   = True,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        # Bi-LSTM on MFCC\n",
    "        self.bdlstm_mfcc = nn.LSTM(\n",
    "            input_size    = n_mfcc,\n",
    "            hidden_size   = hidden_dim,\n",
    "            num_layers    = 1,\n",
    "            batch_first   = True,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        # Unidirectional LSTM after fusion\n",
    "        fused_dim = 2*hidden_dim*2   # mel(2h) + mfcc(2h)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size  = fused_dim,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers  = uni_layers,\n",
    "            batch_first = True\n",
    "        )\n",
    "        # Classifier MLP\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, mel: torch.Tensor, mfcc: torch.Tensor) -> torch.Tensor:\n",
    "        # mel: (B,1,n_mels,T), mfcc: (B,1,n_mfcc,T)\n",
    "        B,_,F_mel,T = mel.shape\n",
    "        _,_,F_mfcc,_= mfcc.shape\n",
    "\n",
    "        # → (B, T, F)\n",
    "        mel = mel.view(B, F_mel, T).permute(0,2,1)\n",
    "        mf  = mfcc.view(B, F_mfcc, T).permute(0,2,1)\n",
    "\n",
    "        # Bi-LSTM branches\n",
    "        mel_feats, _ = self.bdlstm_mel(mel)   # (B,T,2*hidden)\n",
    "        mf_feats,  _ = self.bdlstm_mfcc(mf)  # (B,T,2*hidden)\n",
    "\n",
    "        # fuse\n",
    "        x = torch.cat([mel_feats, mf_feats], dim=2)  # (B,T,4*hidden)\n",
    "\n",
    "        # uni-LSTM\n",
    "        x, _ = self.lstm(x)                          # (B,T,hidden)\n",
    "\n",
    "        # classify last timestep\n",
    "        logits = self.classifier(x[:, -1, :])        # (B,num_classes)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196abb4-9fed-477b-9dc8-ea04455e0168",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c4151-7c9b-4abe-a91a-12dd6f4e7339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] Found 64727 files under 31 classes: ['_background_noise_', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n",
      "Classes (31): ['_background_noise_', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'four', 'go', 'happy', 'house', 'left', 'marvin', 'nine', 'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree', 'two', 'up', 'wow', 'yes', 'zero']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1/50: 100%|██████████| 203/203 [03:59<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.8373, Acc=16.74% | Val   Loss=2.3371, Acc=30.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2/50: 100%|██████████| 203/203 [00:53<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=2.2568, Acc=33.67% | Val   Loss=2.0491, Acc=40.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3/50: 100%|██████████| 203/203 [00:55<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=2.0298, Acc=41.06% | Val   Loss=1.8806, Acc=45.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4/50: 100%|██████████| 203/203 [00:54<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=1.8763, Acc=45.69% | Val   Loss=1.8161, Acc=47.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5/50: 100%|██████████| 203/203 [00:52<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=1.8154, Acc=47.68% | Val   Loss=1.7659, Acc=48.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6/50: 100%|██████████| 203/203 [00:50<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=1.7716, Acc=48.71% | Val   Loss=1.7225, Acc=49.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7/50: 100%|██████████| 203/203 [00:49<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=1.7053, Acc=50.63% | Val   Loss=1.7004, Acc=50.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8/50: 100%|██████████| 203/203 [00:48<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=1.6819, Acc=51.42% | Val   Loss=1.6942, Acc=50.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 9/50: 100%|██████████| 203/203 [00:49<00:00,  4.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=1.6636, Acc=51.70% | Val   Loss=1.6845, Acc=50.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 10/50: 100%|██████████| 203/203 [00:46<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=1.6364, Acc=52.50% | Val   Loss=1.6716, Acc=51.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 11/50: 100%|██████████| 203/203 [00:48<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=1.6226, Acc=52.92% | Val   Loss=1.6694, Acc=51.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 12/50: 100%|██████████| 203/203 [00:47<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.6142, Acc=53.18% | Val   Loss=1.6644, Acc=51.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 13/50: 100%|██████████| 203/203 [00:49<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.5970, Acc=53.62% | Val   Loss=1.6594, Acc=51.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 14/50: 100%|██████████| 203/203 [00:46<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=1.5912, Acc=53.84% | Val   Loss=1.6578, Acc=51.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 15/50: 100%|██████████| 203/203 [00:47<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=1.5853, Acc=54.02% | Val   Loss=1.6593, Acc=51.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 16/50:  74%|███████▍  | 150/203 [00:36<00:11,  4.46it/s]"
     ]
    }
   ],
   "source": [
    "# make sure CUDA errors sync\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "# from dataloader import get_dataloaders\n",
    "# from models      import SbuLSTMFusion\n",
    "\n",
    "def main():\n",
    "    # hyper‐params\n",
    "    root_dir      = '/capstor/scratch/cscs/ckuya/speech-data/train/audio/'\n",
    "    mel_dim       = 40\n",
    "    mfcc_dim      = 13\n",
    "    max_len       = 20\n",
    "    batch_size    = 256\n",
    "    val_frac      = 0.2\n",
    "    epochs        = 50\n",
    "    lr            = 1e-3\n",
    "    weight_decay  = 1e-5\n",
    "    step_size     = 3\n",
    "    gamma         = 0.5\n",
    "    hidden_dim    = 128\n",
    "    uni_layers    = 1\n",
    "    dropout       = 0.3\n",
    "    num_workers   = 4\n",
    "    exclude_folders = []\n",
    "\n",
    "    # 1) Data\n",
    "    train_loader, val_loader, num_classes, label_map = get_dataloaders(\n",
    "        root_dir        = root_dir,\n",
    "        mel_dim         = mel_dim,\n",
    "        mfcc_dim        = mfcc_dim,\n",
    "        max_len         = max_len,\n",
    "        batch_size      = batch_size,\n",
    "        val_frac        = val_frac,\n",
    "        num_workers     = num_workers,\n",
    "        exclude_folders = exclude_folders\n",
    "    )\n",
    "    print(f\"Classes ({num_classes}): {list(label_map.keys())}\")\n",
    "\n",
    "    # 2) Model / Optim / Scheduler / Loss\n",
    "    device   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model    = SbuLSTMFusion(\n",
    "        n_mels     = mel_dim,\n",
    "        n_mfcc     = mfcc_dim,\n",
    "        hidden_dim = hidden_dim,\n",
    "        uni_layers = uni_layers,\n",
    "        num_classes= num_classes,\n",
    "        dropout    = dropout\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=step_size,\n",
    "        gamma=gamma\n",
    "    )\n",
    "\n",
    "    # 3) Train + Validate\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # ——— TRAIN ———\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total   = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Train {epoch}/{epochs}\"):\n",
    "            mel   = batch['mel'].unsqueeze(1).to(device)\n",
    "            mfcc  = batch['mfcc'].unsqueeze(1).to(device)\n",
    "            labels= batch['label'].to(device)\n",
    "\n",
    "            logits = model(mel, mfcc)\n",
    "            loss   = criterion(logits, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds==labels).sum().item()\n",
    "            total   += labels.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        train_loss = running_loss/total\n",
    "        train_acc  = 100*correct/total\n",
    "\n",
    "        # ——— VALIDATE ———\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corr = 0\n",
    "        val_tot  = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                mel   = batch['mel'].unsqueeze(1).to(device)\n",
    "                mfcc  = batch['mfcc'].unsqueeze(1).to(device)\n",
    "                labels= batch['label'].to(device)\n",
    "\n",
    "                logits = model(mel, mfcc)\n",
    "                loss   = criterion(logits, labels)\n",
    "                val_loss += loss.item() * labels.size(0)\n",
    "\n",
    "                preds = logits.argmax(dim=1)\n",
    "                val_corr += (preds==labels).sum().item()\n",
    "                val_tot  += labels.size(0)\n",
    "\n",
    "        val_loss /= val_tot\n",
    "        val_acc   = 100*val_corr/val_tot\n",
    "\n",
    "        print(f\"Epoch {epoch}: \"\n",
    "              f\"Train Loss={train_loss:.4f}, Acc={train_acc:.2f}% | \"\n",
    "              f\"Val   Loss={val_loss:.4f}, Acc={val_acc:.2f}%\")\n",
    "\n",
    "        # save best\n",
    "        if val_acc>best_val_acc:\n",
    "            torch.save(model.state_dict(),\"best_sbulstm_fusion1.pth\")\n",
    "            best_val_acc=val_acc\n",
    "\n",
    "    print(f\"Training done → Best Val Acc: {best_val_acc:.2f}%\")\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kws)",
   "language": "python",
   "name": "kws-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
